<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Single-Channel Audio Source Separation Using Deep Neural Network Ensembles</title>
  <meta name="description" content="Musical Audio Repurposing using Source Separation">

  <link rel="stylesheet" href="/maruss-website/assets/main.css">
  <link rel="canonical" href="https://cvssp.github.io/maruss-website/publications/Grais_2016.html">
  <link rel="alternate" type="application/rss+xml" title="MARuSS" href="/maruss-website/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
      <h1>MARuSS</h1>
      <h2>Musical Audio Repurposing using Source Separation
<h2>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
        
          <a class="page-link" href="/maruss-website/about/">About</a>
        
        
        
          <a class="page-link" href="/maruss-website/">Home</a>
        
        
        
        
        
          <a class="page-link" href="/maruss-website/people/">People</a>
        
        
        
          <a class="page-link" href="/maruss-website/publications/">Publications</a>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Single-Channel Audio Source Separation Using Deep Neural Network Ensembles</h1>
  </header>

  <div class="post-content">
    <ul>



<li><p>Link: <a href="http://www.aes.org/e-lib/browse.cfm?elib=18193">http://www.aes.org/e-lib/browse.cfm?elib=18193</a></p></li>

</ul>


<h2> Abstract </h2>
Deep neural networks (DNNs) are often used to tackle the single
        channel source separation (SCSS) problem by predicting time-frequency
            masks. The predicted masks are then used to separate the sources
            from the mixed signal. Different types of masks produce separated
            sources with different levels of distortion and interference. Some
            types of masks produce separated sources with low distortion, while
            other masks produce low interference between the separated sources.
            In this paper a combination of different DNNsâ€™ predictions (masks)
            is used for SCSS to achieve better quality of the separated sources
            than using each DNN individually. We train four different DNNs by
            minimizing four different cost functions to predict four different
            masks. The first and second DNNs are trained to approximate
            reference binary and soft masks. The third DNN is trained to predict
            a mask from the reference sources directly. The last DNN is trained
            similarly to the third DNN but with an additional discriminative
            constraint to maximize the differences between the estimated
            sources. Our experimental results show that combining the
            predictions of different DNNs achieves separated sources with better
            quality than using each DNN individually.



<h2> Bibtex </h2>
<pre>
<code class='language-bibtex'>
@conference{Grais_2016,
  title = {Single-Channel Audio Source Separation Using Deep Neural Network Ensembles},
  author = {Grais, E. M. and Roma, G. and Simpson, A. J. R. and Plumbley, M. D.},
  booktitle = {Audio Engineering Society Convention 140},
  month = may,
  year = {2016},
  address = {Paris, France},
  url = {http://www.aes.org/e-lib/browse.cfm?elib=18193},
  keywords = {"maruss"}
}

</code>
</pre>



<!-- Bit of a hack but does the job -->

    
        
            <h2 id="implementation">Implementation</h2>

<p>You can download (beta) the code <a href="http://cvssp.org/download/dnnensemblescss.tar.gz">here</a>.
The software is distributed under BSD license. If you use it, please cite us.</p>

        

        

        


  </div>

</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">MARuSS</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              
            
            </li>
            
            <li><a href="mailto:contact email">contact email</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          

          
        </ul>
      </div>

      <!--
      <div class="footer-col footer-col-3">
        <p>Musical Audio Repurposing using Source Separation
</p>
      </div>
        -->
    </div>

  </div>

</footer>


  </body>

</html>
